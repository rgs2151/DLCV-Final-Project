{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hand segmentation.ipynb","provenance":[],"mount_file_id":"1m_eV5DPGdYrH4-q_43W0WvmZv3o4Eh2a","authorship_tag":"ABX9TyMi729xds9/VGWcOK8FDa2U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["\n","!cp /content/drive/MyDrive/handmask/hands.pth.tar -r /content/weights\n"],"metadata":{"id":"-72GlCSOF8Fi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/adarsh1001/Hand_Segmentation_RefineNet\n","!cp /content/Hand_Segmentation_RefineNet/RefineNet/refinenet.py -r /content\n","!cp /content/Hand_Segmentation_RefineNet/RefineNet/weights -r /content\n","!cp /content/drive/MyDrive/handmask/hands.pth.tar -r /content/weights\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzuaBr5H8JR2","executionInfo":{"status":"ok","timestamp":1651139185963,"user_tz":-330,"elapsed":3568,"user":{"displayName":"azyo asl","userId":"17530650473661026803"}},"outputId":"9c27c254-70fb-4e4e-f43d-e99b8fa94aee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Hand_Segmentation_RefineNet'...\n","remote: Enumerating objects: 45, done.\u001b[K\n","remote: Total 45 (delta 0), reused 0 (delta 0), pack-reused 45\u001b[K\n","Unpacking objects: 100% (45/45), done.\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"wnNY6AUHkbvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import glob\n","from pathlib import Path\n","from csv import writer\n","import cv2\n","from cv2 import VideoCapture, waitKey, imshow, cvtColor, flip, COLOR_BGR2RGB, COLOR_RGB2BGR, putText, FONT_HERSHEY_SIMPLEX, resize, rectangle, line, VideoWriter_fourcc, VideoWriter\n","from numpy import asscalar, ndarray, array, zeros, concatenate, load, uint8, set_printoptions, inf\n","from pathlib import Path\n","from shutil import rmtree\n","import random\n","from os.path import split\n","import matplotlib.pyplot as plt\n","import re\n","import torch\n","from refinenet import refinenet\n","from tqdm import tqdm\n","\n","cmap = np.load('weights/cmap.npy')\n","img_dir = '/content/images/'\n","\n","\n","# vid_dir = '/content/video'\n","# vids = os.listdir(vid_dir)\n","\n","numC = 7\n","\n","img_scale = 1./255\n","img_mean = np.array([0.485, 0.456, 0.406]).reshape((1, 1, 3))\n","img_std = np.array([0.229, 0.224, 0.225]).reshape((1, 1, 3))\n","\n","net = refinenet(numC, pretrained=True).eval()\n","net = net.cuda() #Run only with Cuda support!\n","idx = 1\n","\n","\n","current_ds = '/content/Age_2.avi'\n","video = current_ds\n","video_cap = VideoCapture(str(video))\n","flag, frame = video_cap.read()\n","cnt =1\n","frame_length = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","rmtree('/content/images')\n","Path('/content/images').mkdir()\n","\n","while flag:\n","    cv2.imwrite('/content/images/frame%d.jpg' %cnt, frame)\n","    flag, frame = video_cap.read()\n","    cnt+=1\n","\n","\n","imgs = os.listdir(img_dir)\n","if Path('/content/segmented_images/').exists():rmtree('/content/segmented_images/')\n","Path('/content/segmented_images/').mkdir()\n","with torch.no_grad():\n","\n","    for img in imgs:\n","        if img!='.ipynb_checkpoints':\n","            img_path = img_dir + img\n","            # img_path = '/content/new_images/hand.webp'\n","            print(img)\n","            img_name=img\n","            img = np.array(plt.imread(img_path))\n","            \n","            orig_size = img.shape[:2][::-1]\n","\n","            inter_img = (img*img_scale - img_mean)/img_std\n","\n","            img_inp = torch.tensor(inter_img.transpose(2, 0, 1)[None]).float()\n","            img_inp = img_inp.cuda()\n","\n","            seg = net(img_inp)[0].data.cpu().numpy().transpose(1, 2, 0)\n","            seg = cv2.resize(seg, orig_size, interpolation=cv2.INTER_CUBIC)\n","            seg = cmap[seg.argmax(axis=2).astype(np.uint8)]\n","\n","            ma = (seg[:,:,0]>=0) & (seg[:,:,0]<=20) & (seg[:,:,2]>=110) & (seg[:,:,2]<=150) & (seg[:,:,1]>=0) & (seg[:,:,1]<=20)\n","            x = np.zeros(ma.shape)\n","            x[ma==True] = 255\n","            x[ma==False] = 0\n","            print(len(x))\n","            import numpy\n","            # with numpy.printoptions(threshold=numpy.inf):\n","            #     print(x)\n","            #     break\n","            print('/content/segmented_images/'+str(img_name))\n","            cv2.imwrite('/content/segmented_images/'+str(img_name),x)\n","            idx += 1\n","            print('done')\n"],"metadata":{"id":"g_qqxtZy6ywz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["segmented_images_folder = ('/content/segmented_images')\n","video_name = ('/content/sample.avi')\n","images = [img for img in os.listdir(segmented_images_folder) if img.endswith(\".jpg\")]\n","frame = cv2.imread(os.path.join(segmented_images_folder, images[0]))\n","height, width, layers = frame.shape\n","print(images)\n","video = cv2.VideoWriter(video_name, 0, 10, (width,height))\n","\n","for img in images:\n","    frame = np.fromfile('segmented_images/'+img, dtype='int16', sep=\"\")\n","    print(frame)\n","    video.write(frame)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"StG4B7f1lOzj","executionInfo":{"status":"error","timestamp":1651139596241,"user_tz":-330,"elapsed":5,"user":{"displayName":"azyo asl","userId":"17530650473661026803"}},"outputId":"d6857aac-1641-42ae-9b9e-801767ebfbfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['frame2.jpg', 'frame39.jpg', 'frame35.jpg', 'frame42.jpg', 'frame30.jpg', 'frame41.jpg', 'frame10.jpg', 'frame43.jpg', 'frame15.jpg', 'frame46.jpg', 'frame7.jpg', 'frame34.jpg', 'frame11.jpg', 'frame16.jpg', 'frame12.jpg', 'frame32.jpg', 'frame47.jpg', 'frame24.jpg', 'frame37.jpg', 'frame29.jpg', 'frame50.jpg', 'frame31.jpg', 'frame33.jpg', 'frame5.jpg', 'frame22.jpg', 'frame17.jpg', 'frame8.jpg', 'frame19.jpg', 'frame28.jpg', 'frame40.jpg', 'frame45.jpg', 'frame21.jpg', 'frame3.jpg', 'frame44.jpg', 'frame26.jpg', 'frame14.jpg', 'frame18.jpg', 'frame1.jpg', 'frame23.jpg', 'frame38.jpg', 'frame6.jpg', 'frame25.jpg', 'frame13.jpg', 'frame27.jpg', 'frame9.jpg', 'frame48.jpg', 'frame49.jpg', 'frame20.jpg', 'frame4.jpg', 'frame36.jpg']\n","[-9985 -7937  4096 ...  5189 24401 -9729]\n"]},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-5f4b93f68c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'segmented_images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/videoio/src/cap_ffmpeg.cpp:144: error: (-215:Assertion failed) image.depth() == CV_8U in function 'write'\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from pathlib import Path\n","\n","all_img_path = list((Path(\"/content/segmented_images\")).glob(\"*\"))\n","print(len(all_img_path))\n","# choose codec according to format needed\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPpxKrPN-1_B","executionInfo":{"status":"ok","timestamp":1650106170049,"user_tz":-330,"elapsed":442,"user":{"displayName":"azyo asl","userId":"17530650473661026803"}},"outputId":"577647b0-5bba-486b-8845-fe98e8f5ad4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50\n"]}]},{"cell_type":"code","source":["!zip -r /content/sample.zip /content/segmented_images"],"metadata":{"id":"6x_cC8wC_sj9"},"execution_count":null,"outputs":[]}]}